# -*- coding: utf-8 -*-
"""Copy of Capstone Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eHsFPsNd_0GZj6d3f8g2fCOyeRjmockL

#Import Library
"""

import pandas as pd
import numpy as np
import tensorflow as tf
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.metrics import classification_report, mean_absolute_error

"""#Data

##Load Data
"""

data = pd.read_csv("https://raw.githubusercontent.com/rncyspoetra/Hematin-App/refs/heads/main/Machine%20Learning/data_pengeluaran_sintetis%20(final).csv")

"""##EDA

###Informasi Dataset
"""

print("=== Informasi Dataset ===")
print(data.info())

"""###Statistik Deskriptif"""

print("\n=== Statistik Deskriptif ===")
print(data.describe())

"""###Missing Values"""

print("\n=== Cek Missing Values ===")
print(data.isnull().sum())

"""###Distribusi Saran Penghematan"""

print("\n=== Distribusi Target (Saran Penghematan) ===")
print(data["saving_suggestion"].value_counts())

"""###Visualisasi"""

sns.boxplot(data=data.select_dtypes(include='number'))
plt.xticks(rotation=90)
plt.title("Boxplot Fitur Numerik")
plt.show()

"""##Fitur dan Target"""

X = data.drop(columns=["saving_suggestion", "next_month_spending_prediction"])
y_class_raw = data["saving_suggestion"]
y_reg_raw = data["next_month_spending_prediction"]

label_encoder = LabelEncoder()
y_class_encoded = label_encoder.fit_transform(y_class_raw)
num_classes = len(label_encoder.classes_)

"""##Preprocessing"""

numerical_cols = X.select_dtypes(include=np.number).columns
categorical_cols = X.select_dtypes(include='object').columns

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ],
    remainder='passthrough'
)

"""##Split Data"""

X_train, X_test, y_train_class, y_test_class, y_train_reg, y_test_reg = train_test_split(
    X, y_class_encoded, y_reg_raw, test_size=0.2, random_state=42
)
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

"""#Model

##Model Klasifikasi
"""

class ManualClassifier:
    def __init__(self, input_dim, num_classes, hidden_units=128, dropout_rate=0.3):
        self.W1 = tf.Variable(tf.random.normal([input_dim, hidden_units]), name='W1')
        self.b1 = tf.Variable(tf.zeros([hidden_units]), name='b1')

        self.W2 = tf.Variable(tf.random.normal([hidden_units, hidden_units//2]), name='W2')
        self.b2 = tf.Variable(tf.zeros([hidden_units//2]), name='b2')

        self.W3 = tf.Variable(tf.random.normal([hidden_units//2, num_classes]), name='W3')
        self.b3 = tf.Variable(tf.zeros([num_classes]), name='b3')

        self.dropout_rate = dropout_rate

    def __call__(self, x, training=False):
        x = tf.matmul(x, self.W1) + self.b1
        x = tf.nn.relu(x)
        if training:
            x = tf.nn.dropout(x, rate=self.dropout_rate)

        x = tf.matmul(x, self.W2) + self.b2
        x = tf.nn.relu(x)

        logits = tf.matmul(x, self.W3) + self.b3
        return tf.nn.softmax(logits)

def compute_loss(y_true, y_pred):
    return tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred))

def compute_accuracy(y_true, y_pred):
    pred_labels = tf.argmax(y_pred, axis=1)
    return tf.reduce_mean(tf.cast(tf.equal(pred_labels, tf.cast(y_true, tf.int64)), tf.float32))

def train(model, X_train, y_train, X_val, y_val, learning_rate=0.001, epochs=20, batch_size=32):
    optimizer = tf.optimizers.Adam(learning_rate)
    dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=1024).batch(batch_size)

    for epoch in range(epochs):
        epoch_loss = 0
        for step, (x_batch, y_batch) in enumerate(dataset):
            with tf.GradientTape() as tape:
                y_pred = model(x_batch, training=True)
                loss = compute_loss(y_batch, y_pred)
            grads = tape.gradient(loss, [model.W1, model.b1, model.W2, model.b2, model.W3, model.b3])
            optimizer.apply_gradients(zip(grads, [model.W1, model.b1, model.W2, model.b2, model.W3, model.b3]))
            epoch_loss += loss.numpy()

        val_pred = model(X_val, training=False)
        val_acc = compute_accuracy(y_val, val_pred).numpy()
        print(f"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Val Accuracy: {val_acc:.4f}")

input_dim = X_train_processed.shape[1]
num_classes = len(np.unique(y_train_class))

X_train_tensor = tf.convert_to_tensor(X_train_processed, dtype=tf.float32)
y_train_tensor = tf.convert_to_tensor(y_train_class, dtype=tf.int32)

X_val_tensor = tf.convert_to_tensor(X_test_processed, dtype=tf.float32)
y_val_tensor = tf.convert_to_tensor(y_test_class, dtype=tf.int32)

model = ManualClassifier(input_dim=input_dim, num_classes=num_classes, hidden_units=128, dropout_rate=0.3)
train(model, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, learning_rate=0.001, epochs=20)

"""##Model Regresi"""

class ManualRegressor:
    def __init__(self, input_dim, hidden_units=128, dropout_rate=0.3):
        self.W1 = tf.Variable(tf.random.normal([input_dim, hidden_units]), name='W1')
        self.b1 = tf.Variable(tf.zeros([hidden_units]), name='b1')

        self.W2 = tf.Variable(tf.random.normal([hidden_units, hidden_units//2]), name='W2')
        self.b2 = tf.Variable(tf.zeros([hidden_units//2]), name='b2')

        self.W3 = tf.Variable(tf.random.normal([hidden_units//2, 1]), name='W3')
        self.b3 = tf.Variable(tf.zeros([1]), name='b3')

        self.dropout_rate = dropout_rate

    def __call__(self, x, training=False):
        x = tf.matmul(x, self.W1) + self.b1
        x = tf.nn.relu(x)
        if training:
            x = tf.nn.dropout(x, rate=self.dropout_rate)

        x = tf.matmul(x, self.W2) + self.b2
        x = tf.nn.relu(x)

        output = tf.matmul(x, self.W3) + self.b3
        return output

def compute_regression_loss(y_true, y_pred):
    return tf.reduce_mean(tf.abs(y_true - y_pred))  # MAE

def train_regression(model, X_train, y_train, X_val, y_val, learning_rate=0.001, epochs=20, batch_size=32):
    optimizer = tf.optimizers.Adam(learning_rate)
    dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=1024).batch(batch_size)

    for epoch in range(epochs):
        epoch_loss = 0
        for step, (x_batch, y_batch) in enumerate(dataset):
            with tf.GradientTape() as tape:
                y_pred = model(x_batch, training=True)
                loss = compute_regression_loss(y_batch, y_pred)
            grads = tape.gradient(loss, [model.W1, model.b1, model.W2, model.b2, model.W3, model.b3])
            optimizer.apply_gradients(zip(grads, [model.W1, model.b1, model.W2, model.b2, model.W3, model.b3]))
            epoch_loss += loss.numpy()

        val_pred = model(X_val, training=False)
        val_mae = compute_regression_loss(y_val, val_pred).numpy()
        print(f"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Val MAE: {val_mae:.4f}")

X_train_tensor_reg = tf.convert_to_tensor(X_train_processed, dtype=tf.float32)
y_train_tensor_reg = tf.convert_to_tensor(y_train_reg, dtype=tf.float32)

X_val_tensor_reg = tf.convert_to_tensor(X_test_processed, dtype=tf.float32)
y_val_tensor_reg = tf.convert_to_tensor(y_test_reg, dtype=tf.float32)

reg_model = ManualRegressor(input_dim=X_train_processed.shape[1], hidden_units=128, dropout_rate=0.3)
train_regression(reg_model, X_train_tensor_reg, y_train_tensor_reg, X_val_tensor_reg, y_val_tensor_reg, learning_rate=0.001, epochs=20)

"""##Evaluasi Model"""

X_test_tensor_cls = tf.convert_to_tensor(X_test_processed, dtype=tf.float32)
y_test_tensor_cls = tf.convert_to_tensor(y_test_class, dtype=tf.int32)

y_pred_proba = model(X_test_tensor_cls, training=False)
accuracy_cls = compute_accuracy(y_test_tensor_cls, y_pred_proba).numpy()
print(f"Akurasi pada data tes: {accuracy_cls:.2%}")

y_pred_class = tf.argmax(y_pred_proba, axis=1).numpy()
print("\nLaporan Klasifikasi Model Terbaik:")
print(classification_report(y_test_class, y_pred_class, target_names=label_encoder.classes_))

X_test_tensor_reg = tf.convert_to_tensor(X_test_processed, dtype=tf.float32)
y_test_tensor_reg = tf.convert_to_tensor(y_test_reg, dtype=tf.float32)

y_pred_reg = reg_model(X_test_tensor_reg, training=False)
mae_reg = compute_regression_loss(y_test_tensor_reg, y_pred_reg).numpy()
print(f"Mean Absolute Error (MAE) pada data tes: Rp {mae_reg:,.2f}")

"""#Input Manual"""

valid_statuses = ['Businessman', 'Freelance', 'Full-time', 'Part-time', 'Contract', 'Student']

print("\n=== Masukkan Data Anda untuk Prediksi ===")
income = float(input("Pendapatan bulanan (contoh: 8000000): "))
fixed_expenses = float(input("Pengeluaran tetap (contoh: 3000000): "))
weekly_food = float(input("Pengeluaran makanan mingguan (contoh: 500000): "))
weekly_transport = float(input("Pengeluaran transport mingguan (contoh: 250000): "))
subscriptions = int(input("Jumlah layanan langganan (contoh: 2): "))
employment_status = input(f"Status pekerjaan {valid_statuses}: ").strip()
while employment_status not in valid_statuses:
    print("‚ùå Status tidak valid.")
    employment_status = input("Masukkan ulang status pekerjaan: ").strip()
age = int(input("Usia (contoh: 30): "))
last_month_spending = float(input("Pengeluaran bulan lalu (contoh: 6500000): "))
savings_last_month = float(input("Tabungan bulan lalu (contoh: 1500000): "))

"""#Dataframe Input"""

user_input_data = pd.DataFrame([{
    "income": income,
    "fixed_expenses": fixed_expenses,
    "weekly_food_spending": weekly_food,
    "weekly_transport_spending": weekly_transport,
    "subscription_services_count": subscriptions,
    "employment_status": employment_status,
    "age": age,
    "last_month_spending": last_month_spending,
    "savings_last_month": savings_last_month
}])

"""#Inference"""

user_input_tensor = tf.convert_to_tensor(user_input_processed, dtype=tf.float32)

suggestion_prediction_proba = model(user_input_tensor, training=False).numpy()
suggestion_prediction_index = np.argmax(suggestion_prediction_proba, axis=1)[0]
suggestion = label_encoder.inverse_transform([suggestion_prediction_index])[0]

spending_prediction_tensor = reg_model(user_input_tensor, training=False).numpy()
spending_prediction = spending_prediction_tensor[0][0]

"""#Output"""

print("\nüìä HASIL PREDIKSI")
print(f"üí∞ Prediksi Pengeluaran Bulan Depan: Rp {spending_prediction:,.0f}")
print(f"üí° Saran Penghematan: {suggestion}")