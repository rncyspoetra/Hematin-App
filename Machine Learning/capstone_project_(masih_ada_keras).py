# -*- coding: utf-8 -*-
"""Capstone Project (Masih ada keras)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FiyZtxlSz0fmLlQ__YN1ecNxLfotq5Vp
"""

!pip install keras_tuner

"""#Import Library"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import keras_tuner as kt
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.metrics import classification_report, mean_absolute_error

"""#Data

##Load Data
"""

data = pd.read_csv("https://raw.githubusercontent.com/rncyspoetra/Hematin-App/refs/heads/main/Machine%20Learning/data_pengeluaran_sintetis%20(final).csv")

"""##EDA

###Informasi Dataset
"""

print("=== Informasi Dataset ===")
print(data.info())

"""###Statistik Deskriptif"""

print("\n=== Statistik Deskriptif ===")
print(data.describe())

"""###Missing Values"""

print("\n=== Cek Missing Values ===")
print(data.isnull().sum())

"""###Distribusi Saran Penghematan"""

print("\n=== Distribusi Target (Saran Penghematan) ===")
print(data["saving_suggestion"].value_counts())

"""###Visualisasi"""

sns.boxplot(data=data.select_dtypes(include='number'))
plt.xticks(rotation=90)
plt.title("Boxplot Fitur Numerik")
plt.show()

"""##Fitur dan Target"""

X = data.drop(columns=["saving_suggestion", "next_month_spending_prediction"])
y_class_raw = data["saving_suggestion"]
y_reg_raw = data["next_month_spending_prediction"]

label_encoder = LabelEncoder()
y_class_encoded = label_encoder.fit_transform(y_class_raw)
num_classes = len(label_encoder.classes_)

"""##Preprocessing"""

numerical_cols = X.select_dtypes(include=np.number).columns
categorical_cols = X.select_dtypes(include='object').columns

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ],
    remainder='passthrough'
)

"""##Split Data"""

X_train, X_test, y_train_class, y_test_class, y_train_reg, y_test_reg = train_test_split(
    X, y_class_encoded, y_reg_raw, test_size=0.2, random_state=42
)
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

"""#Model

##Model Klasifikasi
"""

def build_classification_model(hp):
    model = keras.Sequential()
    model.add(layers.Input(shape=(X_train_processed.shape[1],)))
    hp_units_1 = hp.Int('cls_units_1', min_value=64, max_value=256, step=64)
    hp_dropout = hp.Float('cls_dropout', min_value=0.2, max_value=0.5, step=0.1)
    hp_learning_rate = hp.Choice('cls_learning_rate', values=[1e-2, 1e-3])
    model.add(layers.Dense(units=hp_units_1, activation='relu'))
    model.add(layers.Dropout(rate=hp_dropout))
    model.add(layers.Dense(units=hp_units_1 // 2, activation='relu'))
    model.add(layers.Dense(num_classes, activation='softmax'))
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

"""##Model Regresi"""

def build_regression_model(hp):
    model = keras.Sequential()
    model.add(layers.Input(shape=(X_train_processed.shape[1],)))
    hp_units_1 = hp.Int('reg_units_1', min_value=64, max_value=256, step=64)
    hp_dropout = hp.Float('reg_dropout', min_value=0.2, max_value=0.5, step=0.1)
    hp_learning_rate = hp.Choice('reg_learning_rate', values=[1e-2, 1e-3])
    model.add(layers.Dense(units=hp_units_1, activation='relu'))
    model.add(layers.Dropout(rate=hp_dropout))
    model.add(layers.Dense(units=hp_units_1 // 2, activation='relu'))
    model.add(layers.Dense(1))
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate), loss='mean_absolute_error', metrics=['mae'])
    return model

"""##Tuning Klasifikasi"""

stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)

tuner_cls = kt.Hyperband(
    hypermodel=build_classification_model,
    objective='val_accuracy',
    max_epochs=15,
    factor=3,
    directory='keras_tuner_dir',
    project_name='finance_classification',
    overwrite=True
)
tuner_cls.search(X_train_processed, y_train_class, epochs=15, validation_data=(X_test_processed, y_test_class), callbacks=[stop_early])
best_hps_cls = tuner_cls.get_best_hyperparameters(num_trials=1)[0]
tuned_classifier = tuner_cls.hypermodel.build(best_hps_cls)
tuned_classifier.fit(X_train_processed, y_train_class, epochs=15, validation_data=(X_test_processed, y_test_class), callbacks=[stop_early], verbose=0)

"""##Tuning Regresi"""

tuner_reg = kt.Hyperband(
    hypermodel=build_regression_model,
    objective=kt.Objective('val_mae', direction='min'),
    max_epochs=15,
    factor=3,
    directory='keras_tuner_dir',
    project_name='finance_regression',
    overwrite=True
)
tuner_reg.search(X_train_processed, y_train_reg, epochs=15, validation_data=(X_test_processed, y_test_reg), callbacks=[stop_early])
best_hps_reg = tuner_reg.get_best_hyperparameters(num_trials=1)[0]
tuned_regressor = tuner_reg.hypermodel.build(best_hps_reg)
tuned_regressor.fit(X_train_processed, y_train_reg, epochs=15, validation_data=(X_test_processed, y_test_reg), callbacks=[stop_early], verbose=0)

"""##Training Model Klasifikasi"""

cls_model = build_classification_model(best_hps_cls)
cls_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
cls_model.fit(X_train_processed, y_train_class, epochs=20, validation_split=0.2)
cls_model.save("model_klasifikasi.h5")
cls_model.save("model_klasifikasi.keras")

"""##Training Model Regresi"""

reg_model = build_regression_model(best_hps_reg)
reg_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
reg_model.fit(X_train_processed, y_train_reg, epochs=20, validation_split=0.2)
reg_model.save("model_regresi.h5")
reg_model.save("model_regresi.keras")

"""##Evaluasi Model"""

loss_cls, accuracy_cls = tuned_classifier.evaluate(X_test_processed, y_test_class)
print(f"Akurasi pada data tes: {accuracy_cls:.2%}")
y_pred_proba = tuned_classifier.predict(X_test_processed)
y_pred_class = np.argmax(y_pred_proba, axis=1)
print("\nLaporan Klasifikasi Model Terbaik:")
print(classification_report(y_test_class, y_pred_class, target_names=label_encoder.classes_))


print("\n\n=== Evaluasi Model Regresi Setelah Fine-Tuning ===")
loss_reg, mae_reg = tuned_regressor.evaluate(X_test_processed, y_test_reg)
print(f"Mean Absolute Error (MAE) pada data tes: Rp {mae_reg:,.2f}")

"""#Input Manual"""

valid_statuses = ['Businessman', 'Freelance', 'Full-time', 'Part-time', 'Contract', 'Student']

print("\n=== Masukkan Data Anda untuk Prediksi ===")
income = float(input("Pendapatan bulanan (contoh: 8000000): "))
fixed_expenses = float(input("Pengeluaran tetap (contoh: 3000000): "))
weekly_food = float(input("Pengeluaran makanan mingguan (contoh: 500000): "))
weekly_transport = float(input("Pengeluaran transport mingguan (contoh: 250000): "))
subscriptions = int(input("Jumlah layanan langganan (contoh: 2): "))
employment_status = input(f"Status pekerjaan {valid_statuses}: ").strip()
while employment_status not in valid_statuses:
    print("‚ùå Status tidak valid.")
    employment_status = input("Masukkan ulang status pekerjaan: ").strip()
age = int(input("Usia (contoh: 30): "))
last_month_spending = float(input("Pengeluaran bulan lalu (contoh: 6500000): "))
savings_last_month = float(input("Tabungan bulan lalu (contoh: 1500000): "))

"""#Dataframe Input"""

user_input_data = pd.DataFrame([{
    "income": income,
    "fixed_expenses": fixed_expenses,
    "weekly_food_spending": weekly_food,
    "weekly_transport_spending": weekly_transport,
    "subscription_services_count": subscriptions,
    "employment_status": employment_status,
    "age": age,
    "last_month_spending": last_month_spending,
    "savings_last_month": savings_last_month
}])

"""#Inference"""

user_input_processed = preprocessor.transform(user_input_data)
suggestion_prediction_proba = tuned_classifier.predict(user_input_processed)
suggestion_prediction_index = np.argmax(suggestion_prediction_proba, axis=1)[0]
suggestion = label_encoder.inverse_transform([suggestion_prediction_index])[0]

spending_prediction = tuned_regressor.predict(user_input_processed)[0][0]

"""#Output"""

print("\nüìä HASIL PREDIKSI")
print(f"üí∞ Prediksi Pengeluaran Bulan Depan: Rp {spending_prediction:,.0f}")
print(f"üí° Saran Penghematan: {suggestion}")